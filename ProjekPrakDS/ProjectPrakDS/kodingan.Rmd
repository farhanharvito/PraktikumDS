---
title: "kodingan"
author: "123200029 & 123200121"
date: "2022-11-28"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tm)
library(wordcloud2)
library(vroom)
library(here)
library(RTextTools)
library(dplyr)
library(wordcloud)
library(shiny)
library(ggplot2)
library(plotly)
```
```{r}
datasets <-  read.csv("ReviewTopedCleaned1.csv")
View(datasets)
```

```{r Sentimen Analisis Naive Bayes Classifier}
library(e1071) #Untuk Naive Bayes
library(caret) #untuk Klasifikasi Data
library(syuzhet) #untuk membaca fungsi get_nrc

data <- read.csv("ReviewTopedCleaned1.csv", stringsAsFactors =  FALSE)
review <- as.character(data$text) #merubah text menjadi char
s <- get_nrc_sentiment(review)

review_combine <- cbind(data$text,s) #klasifikasi Data
par(mar=rep(3,4))
a <- barplot(colSums(s), col=rainbow(10),ylab='count',main='Sentiment Analisis Pelanggan Tokopedia')
brplt <- a
```
Memanggil library tambahan yang akan digunakan untuk penggunaan corpus dalam proses cleaning data selanjutnya, Mengatur seed generator bilangan acak R, yang berguna untuk membuat simulasi atau objek acak yang dapat direproduksi.

```{r}
require (corpus)
df<-read.csv("ReviewTopedCleaned1.csv",stringsAsFactors = FALSE)
glimpse(df)
set.seed(20)
df<-df[sample(nrow(df)),]
df<-df[sample(nrow(df)),]
glimpse(df)
corpus<-Corpus(VectorSource(df$text))
corpus
inspect(corpus[1:10])
#fungsinya untuk membersihkan data data yang tidak dibutuhkan 
corpus.clean<-corpus%>%
    tm_map(content_transformer(tolower))%>%
    tm_map(removePunctuation)%>%
    tm_map(removeNumbers)%>%
    tm_map(removeWords, c("yang", "dan", "dari", "tokopedia", "ini", "kita", "untuk" ,"nya","aasi","ongkir","tokoa","gak","transaksi","belanja","toko","gratis","barang"))%>%
    tm_map(removeWords,stopwords(kind="en"))%>%
    tm_map(stripWhitespace)
dtm<-DocumentTermMatrix(corpus.clean)
inspect(dtm[1:10,1:20])
df.train<-df[1:50,]
df.test<-df[51:100,]                                            
dtm.train<-dtm[1:50,]
dtm.test<-dtm[51:100,]
corpus.clean.train<-corpus.clean[1:50]
corpus.clean.test<-corpus.clean[51:100]
dim(dtm.train)
fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)
dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))
#dim(dtm.train.nb)
dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))
dim(dtm.test.nb)
 
convert_count <- function(x){
    y<-ifelse(x>0,1,0)
    y<-factor(y,levels=c(0,1),labels=c("no","yes"))
    y
}
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,1,convert_count)
wordcloud(corpus.clean,min.freq = 4,max.words=100,random.order=F,colors=brewer.pal(8,"Dark2"))
kalimat2<-read.csv("ReviewTopedCleaned1.csv",header=TRUE)
#skoring
kata.positif <- scan("kata-pos.txt",what="character",comment.char=";")
kata.negatif <- scan("kata-neg.txt",what="character",comment.char=";")
score.sentiment = function(kalimat2, kata.positif, kata.negatif,
                           .progress='none')
{
  require(plyr)
  require(stringr)
  scores = laply(kalimat2, function(kalimat, kata.positif,
                                    kata.negatif) {
    kalimat = gsub('[[:punct:]]', '', kalimat)
    kalimat = gsub('[[:cntrl:]]', '', kalimat)
    kalimat = gsub('\\d+', '', kalimat)
    kalimat = tolower(kalimat)
    list.kata = str_split(kalimat, '\\s+')
    kata2 = unlist(list.kata)
    positif.matches = match(kata2, kata.positif)
    negatif.matches = match(kata2, kata.negatif)
    positif.matches = !is.na(positif.matches)
    negatif.matches = !is.na(negatif.matches)
    score = sum(positif.matches) - (sum(negatif.matches))
    return(score)
  }, kata.positif, kata.negatif, .progress=.progress )
  scores.df = data.frame(score=scores, text=kalimat2)
  return(scores.df)}
hasil = score.sentiment(kalimat2$text, kata.positif, kata.negatif)
#mengubah nilai score menjadi sentimen
hasil$klasifikasi<- ifelse(hasil$score<0, "Negatif",ifelse(hasil$score==0,"Netral","Positif"))
hasil$klasifikasi
#menukar urutan baris
data <- hasil[c(3,1,2)]
#View(data)
write.csv(data, file = "datalabel.csv")

```
Pengolahan serta pemodelan dari sebuah data yang telah di olah sebelumnya hingga menampilkan pada GUI dengann Library Shiny

```{r}

library(syuzhet) #untuk membaca fungsi get_nrc
dataLabel<- read.csv("datalabel.csv")

ui <- fluidPage(
    titlePanel("Sentimen Analisis Tokopedia"),
        mainPanel(
            
            tabsetPanel(type = "tabs",
                        tabPanel("BarPlot", plotOutput("scatterplot")), 
                        # Plot
                        tabPanel("Skor", DT::dataTableOutput('tbl1')),
                        # Output Data Dalam Tabel
                        tabPanel("Wordcloud", plotOutput("Wordcloud")),
                        #Output Frequensi
                        tabPanel("FreqWord", plotOutput("freqplot"))
                        )
        )
    )
# SERVER
server <- function(input, output) {
    
    # Output Data
    output$tbl1 = DT::renderDataTable({
        DT::datatable(dataLabel, options = list(lengthChange = FALSE))
    })
    
    output$scatterplot <- renderPlot({produk_dataset<-read.csv("ReviewTopedCleaned1.csv",stringsAsFactors = FALSE)
      review <-as.character(produk_dataset$text)
      s<-get_nrc_sentiment(review)
      review_combine<-cbind(produk_dataset$text,s)
      par(mar=rep(3,4))
      barplot(colSums(s),col=rainbow(10),ylab='count',main='Sentimen Analisis Tokopedia')
          }, height=400)
    # Output Freq Plot
    output$freqplot <- renderPlot({data1 = read.csv("ReviewTopedCleaned1.csv")
    corpus = Corpus(VectorSource(data1$text))
    corpus<- tm_map(corpus, gsub, pattern="aasi","aasinya", replacement="belanja")
    corpus <- tm_map(corpus, removeWords,"tokopedia")
    corpus <- tm_map(corpus, removeWords,"nya")
    corpus <- tm_map(corpus, removeWords,"aja")
    corpus <- tm_map(corpus, removeWords,"gak")
    corpus <- tm_map(corpus, removeWords,"ongkir")
    corpus <- tm_map(corpus, removeWords,"tokoa")
    corpus <- tm_map(corpus, removeWords,"gak")
    corpus <- tm_map(corpus, removeWords,"transaksi")
    corpus <- tm_map(corpus, removeWords,"belanja")
    corpus <- tm_map(corpus, removeWords,"toko")
    corpus <- tm_map(corpus, removeWords,"gratis")
    corpus <- tm_map(corpus, removeWords,"barang")
    
    dtm <- TermDocumentMatrix(corpus)
    m <- as.matrix(dtm)
    v <- sort(rowSums(m),decreasing=TRUE)
    d <- data.frame(word = names(v),freq=v)

  barplot(d[1:20,]$freq, las = 2, names.arg = d[1:20,]$word, col=rainbow(5),
        main = "Kata Paling Sering Muncul", ylab = "Frekuensi")
          }, height=400)
    output$Wordcloud <- renderPlot({
     set.seed(20)
      df<-df[sample(nrow(df)),]
      df<-df[sample(nrow(df)),]
      glimpse(df)
      inspect(dtm[1:10,1:20])
      df.train<-df[1:50,]
      df.test<-df[51:100,]
      dtm.train<-dtm[1:50,]
      dtm.test<-dtm[51:100,]
      dim(dtm.train)
      fivefreq<-findFreqTerms(dtm.train,5)
      length(fivefreq)
      dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))
      #dim(dtm.train.nb)
      dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))
      dim(dtm.test.nb)
 
convert_count <- function(x){
    y<-ifelse(x>0,1,0)
    y<-factor(y,levels=c(0,1),labels=c("no","yes"))
    y
}
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,1,convert_count)
wordcloud(corpus.clean,min.freq = 4,max.words=100,random.order=F,colors=brewer.pal(8,"Dark2"))
  })
}
shinyApp(ui = ui, server = server)
```
